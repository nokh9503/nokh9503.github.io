<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="theme" content="Chirpy v2.6.2"><meta name="generator" content="Jekyll v4.1.1" /><meta property="og:title" content="딥러닝 기반 반려견 울음소리 감지와 감정 및 상태 분석(2)" /><meta name="author" content="nokh9503" /><meta property="og:locale" content="en_US" /><meta name="description" content="3. 프로젝트 내용 3.1 제안 방법" /><meta property="og:description" content="3. 프로젝트 내용 3.1 제안 방법" /><link rel="canonical" href="https://nokh9503.github.io/nokh9503.github.io/posts/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%B0%98%EB%A0%A4%EA%B2%AC-%EC%9A%B8%EC%9D%8C%EC%86%8C%EB%A6%AC-%EA%B0%90%EC%A7%80%EC%99%80-%EA%B0%90%EC%A0%95-%EB%B6%84%EC%84%9D(2)/" /><meta property="og:url" content="https://nokh9503.github.io/nokh9503.github.io/posts/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%B0%98%EB%A0%A4%EA%B2%AC-%EC%9A%B8%EC%9D%8C%EC%86%8C%EB%A6%AC-%EA%B0%90%EC%A7%80%EC%99%80-%EA%B0%90%EC%A0%95-%EB%B6%84%EC%84%9D(2)/" /><meta property="og:site_name" content="코딩이 싫은 컴공" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-12-13T01:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="딥러닝 기반 반려견 울음소리 감지와 감정 및 상태 분석(2)" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@nokh9503" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"description":"3. 프로젝트 내용 3.1 제안 방법","url":"https://nokh9503.github.io/nokh9503.github.io/posts/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%B0%98%EB%A0%A4%EA%B2%AC-%EC%9A%B8%EC%9D%8C%EC%86%8C%EB%A6%AC-%EA%B0%90%EC%A7%80%EC%99%80-%EA%B0%90%EC%A0%95-%EB%B6%84%EC%84%9D(2)/","headline":"딥러닝 기반 반려견 울음소리 감지와 감정 및 상태 분석(2)","dateModified":"2020-12-13T22:43:18+09:00","@type":"BlogPosting","datePublished":"2020-12-13T01:00:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://nokh9503.github.io/nokh9503.github.io/posts/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%B0%98%EB%A0%A4%EA%B2%AC-%EC%9A%B8%EC%9D%8C%EC%86%8C%EB%A6%AC-%EA%B0%90%EC%A7%80%EC%99%80-%EA%B0%90%EC%A0%95-%EB%B6%84%EC%84%9D(2)/"},"author":{"@type":"Person","name":"nokh9503"},"@context":"https://schema.org"}</script><title>딥러닝 기반 반려견 울음소리 감지와 감정 및 상태 분석(2) | 코딩이 싫은 컴공</title><link rel="shortcut icon" href="/nokh9503.github.io/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/nokh9503.github.io/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/nokh9503.github.io/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/nokh9503.github.io/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/nokh9503.github.io/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/nokh9503.github.io/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/nokh9503.github.io/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/nokh9503.github.io/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/nokh9503.github.io/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/nokh9503.github.io/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/nokh9503.github.io/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/nokh9503.github.io/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/nokh9503.github.io/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/nokh9503.github.io/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/nokh9503.github.io/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/nokh9503.github.io/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/nokh9503.github.io/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/nokh9503.github.io/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/nokh9503.github.io/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/nokh9503.github.io/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="preload" href="/nokh9503.github.io/assets/css/post.css" as="style"><link rel="stylesheet" href="/nokh9503.github.io/assets/css/post.css"><link rel="preload" as="style" href="/nokh9503.github.io/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/nokh9503.github.io/assets/css/lib/bootstrap-toc.min.css" /> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script async src="/nokh9503.github.io/assets/js/post.min.js"></script> <script defer src="/nokh9503.github.io/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column"><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/nokh9503.github.io/" alt="avatar"> <img src="/nokh9503.github.io/assets/img/profile/me1.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/nokh9503.github.io/">코딩이 싫은 컴공</a></div><div class="site-subtitle font-italic">내가 인공지능이고 인공지능이 나인 물아일체의 경지가 되려고 하는 바보</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/nokh9503.github.io/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item d-flex justify-content-center "> <a href="/nokh9503.github.io/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item d-flex justify-content-center "> <a href="/nokh9503.github.io/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item d-flex justify-content-center "> <a href="/nokh9503.github.io/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item d-flex justify-content-center "> <a href="/nokh9503.github.io/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <span id="mode-toggle-wrapper"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span> <span class="icon-border"></span> <a href="https://github.com/nokh9503" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['example','doamin.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/nokh9503.github.io/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/nokh9503.github.io/"> Posts </a> </span> <span>딥러닝 기반 반려견 울음소리 감지와 감정 및 상태 분석(2)</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>딥러닝 기반 반려견 울음소리 감지와 감정 및 상태 분석(2)</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sun, Dec 13, 2020, 1:00 AM +0900" > Dec 13, 2020 <i class="unloaded">2020-12-13T01:00:00+09:00</i> </span> by <span class="author"> nokh9503 </span></div><div> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Sun, Dec 13, 2020, 10:43 PM +0900" > Dec 13, 2020 <i class="unloaded">2020-12-13T22:43:18+09:00</i> </span></div></div><div class="post-content"><h2 id="3-프로젝트-내용">3. 프로젝트 내용</h2><h3 id="31-제안-방법">3.1 제안 방법</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="/assets/img/ai/project/proposed_method.png" alt="proposed method" /></p><p>  추출한 음원파일을 <code class="language-plaintext highlighter-rouge">Mel-spectrogram</code>으로 변환하고 <strong>frequency scale</strong>, <strong>time-step</strong> 등과 같은 이미지 변환에 대한 <strong>hyper parameter</strong>를 initialize하여 이미지 파일로 만든다.</p><p>  이후 <code class="language-plaintext highlighter-rouge">비지도 학습</code>을 이용하여 입력 값에 대한 label이 주어지지 않은 데이터들을 군집화를 통해 분류하고 특징의 채널 간의 dependency를 분석하고 중요도가 높은 채널에 더 높은 가중치를 부여하는 <code class="language-plaintext highlighter-rouge">attention</code>을 적용하여 mel-spectrogram 이미지의 가장 두드러진 특징을 강조한다. 또한 <em>모바일</em> 이나 <em>임베디드 시스템</em> 과 같은 환경에서도 성능을 유지할 수 있는 CNN 모델인 <code class="language-plaintext highlighter-rouge">Mobile-Net</code>을 이용하여 학습한다.</p><h3 id="32-데이터-추출">3.2 데이터 추출</h3><h4 id="321-audacity">3.2.1 Audacity</h4><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="/assets/img/ai/project/audacity.png" alt="audacity" /></p><ul><li>대표적인 머신러닝 데이터 분석 플랫폼인 <em>Kaggle</em> 과 동영상 플랫폼인 <em>YouTube</em> 를 통해 개의 울음소리에 대한 음원을 <code class="language-plaintext highlighter-rouge">.wav</code> 파일로 만든다.<li>YouTube에서 추출한 데이터는 위의 그림과 같이 감정 인식에 대한 불필요한 정보가 있는 <em>노이즈</em> 와 <em>무음 구간</em> 이 존재하기 때문에 Audacity 프로그램을 사용하여 최대한 <strong>clean</strong>한 파일로 만들어준다.<li>Audacity 프로그램을 사용하면 spectrogram을 확인할 수 있으며, 음원 파일을 편집할 수 있다.</ul><h4 id="322-오디오-편집">3.2.2 오디오 편집</h4><ul><li>딥러닝 기반으로 소리를 이용한 학습 데이터는 정형화된 파일이어야 한다. <code class="language-plaintext highlighter-rouge">3.2.1.</code>에서 소개한 방법으로 노이즈와 무음 구간을 최대한 없앴지만 아직까지는 <strong>raw</strong>한 데이터이기 때문에 10초짜리 오디오 채널이 1개인 음원 데이터로 다시 가공했다.<li>Audacity를 이용하여 데이터를 자르는 방법이 있지만 부정확하고 직접 잘라야 하는 단점이 있었다. 또한, 데이터가 크고 저장공간이 부족했기 때문에 <code class="language-plaintext highlighter-rouge">Google Colab</code>에서 간단한 <code class="language-plaintext highlighter-rouge">Python</code> 코드를 이용하여 가공된 데이터를 드라이브에 저장했다.</ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">pydub</span> <span class="kn">import</span> <span class="n">AudioSegment</span>

<span class="k">def</span> <span class="nf">cutAudio</span><span class="p">(</span><span class="n">input_file</span><span class="p">,</span> <span class="n">maxtime</span><span class="p">):</span>
    <span class="n">t1</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">t2</span> <span class="o">=</span> <span class="n">t1</span> <span class="o">+</span> <span class="mi">10</span>    <span class="c1"># 10초 단위로 끊음
</span>    <span class="n">label_num</span> <span class="o">=</span> <span class="mi">0</span>   <span class="c1"># label 번호를 설정
</span>
    <span class="k">while</span> <span class="n">t1</span> <span class="o">&lt;</span> <span class="n">maxtime</span><span class="p">:</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">t1</span> <span class="o">*</span> <span class="mi">1000</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">t2</span> <span class="o">*</span> <span class="mi">1000</span>
        <span class="n">newAudio</span> <span class="o">=</span> <span class="n">AudioSegment</span><span class="p">.</span><span class="n">from_wav</span><span class="p">(</span><span class="n">input_file</span><span class="p">)</span>
        <span class="n">newAudio</span> <span class="o">=</span> <span class="n">newAudio</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
        <span class="n">newAudio</span> <span class="o">=</span> <span class="n">newAudio</span><span class="p">.</span><span class="n">set_channels</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">newAudio</span><span class="p">.</span><span class="n">export</span><span class="p">(</span><span class="s">'path where new audio export'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">label_num</span><span class="p">)</span> <span class="o">+</span> <span class="s">'.wav'</span><span class="p">,</span> <span class="nb">format</span> <span class="o">=</span> <span class="s">"wav"</span><span class="p">)</span>        <span class="c1"># 새로운 형태로 export
</span>
        <span class="n">label_num</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">t1</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">t2</span> <span class="o">+=</span> <span class="mi">2</span>

<span class="c1"># main program
</span><span class="n">cutAudio</span><span class="p">(</span><span class="s">"file name"</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>
</pre></table></code></div></div><h4 id="323-mel-spectrogram-변환">3.2.3 Mel-Spectrogram 변환</h4><ul><li><strong>주파수 성분</strong>은 소리 데이터의 가장 특징적인 요소 중 하나이며 <code class="language-plaintext highlighter-rouge">Mel-Spectrogram</code>은 인간의 청각에 맞게 시간과 주파수 축이 <strong>멜 스케일</strong>로 변환되는 소리 데이터 이미지이다. 따라서 Mel-Spectrogram 이미지를 사용하면 소리에 대한 특징 및 클러스터를 쉽게 식별할 수 있다.<li><code class="language-plaintext highlighter-rouge">Librosa</code>는 Python에서 많이 쓰는 음성 파일 분석 패키지로 음성 파일을 Mel-Spectrogram으로 <strong>시각화</strong>할 수 있다.</ul><h3 id="33-데이터-전처리">3.3 데이터 전처리</h3><h4 id="331-hierarchical-clustering">3.3.1 Hierarchical Clustering</h4><p>  반려동물은 복잡하고 다양한 감정들을 표현할 수 있다. 하지만 사람과는 달리 말을 통해 의사소통을 못하기 때문에 예를 들면 같은 짓는 소리여도 기뻐서 짓는 건지 화가 나서 짓는 건지 소리만 듣고 구분하기 어렵다.</p><p>  따라서 데이터들에서 서로 가까운 2개의 점을 찾고 그 점을 합쳐 하나로 만들어주고, 이 결과로 새로운 상위점을 만드는 과정을 반복하는 <code class="language-plaintext highlighter-rouge">Hierarchical Clustering(계층적 군집화)</code>을 이용하여 군집의 유사성에 따라 분류했다.</p><p>  Hierarchical Clustering은 트리 모형을 이용해 개별 개체들을 <strong>순차적</strong>, <strong>계층적</strong>으로 유사한 개체 내지 그룹과 통합하여 군집화를 수행하는 알고리즘이다. <code class="language-plaintext highlighter-rouge">K-means</code>와 달리 군집 수를 사전에 정의하지 않아도 학습을 수행할 수 있다. 개체들이 결합되는 순서를 아래 그림과 같은 트리형태의 구조인 <code class="language-plaintext highlighter-rouge">덴드로그램</code>으로 나타낼 수 있기 때문이다.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="/assets/img/ai/project/dendrogram.png" alt="dendrogram" /></p><h4 id="332-data-augmentation">3.3.2 Data Augmentation</h4><p>  <code class="language-plaintext highlighter-rouge">딥러닝</code>의 고질적인 문제는 여러가지 있는데 그 중 대표적인 문제가 <code class="language-plaintext highlighter-rouge">Overfitting(과잉적합)</code>이다. Overfitting을 해결하기 위한 고전적인 방법으로는 <em>Regularizaion</em>, <em>Normalization</em> 인 모델링 수정이다. 하지만 이러한 방법은 <strong>편향 학습 방향</strong>을 조급 줄이는 정도이다. 즉, 결과적으로 overfitting을 완벽히 해결하는 기술이 되진 않는다.</p><p>  이미지 데이터에서 <code class="language-plaintext highlighter-rouge">Augumentation</code>은 <em>알고리즘</em> 적인 해결방법이 아니라, <em>공학적 접근</em> 을 통한 추론을 위한 전처리 기술 중 하나이다. 원본 이미지에 인위적인 변화를 줘서 이미지를 충분히 학습에 활용될 수 있는 데이터로 만드는 기술이다.</p><p>  Data Augmentation은 기존의 데이터의 정보량을 <strong>보존</strong>한 상태로 <strong>노이즈</strong>를 주는 방식이다. 단지 정보량에 약간의 변화를 주는 것으로, 딥러닝으로 분석된 데이터의 강력하게 표현되는 고유의 특징을 느슨하게 만드는 것이다. 이는 결과적으로 overfitting을 막아줄 수 있고 예측 범위를 약간 넓혀줄 수 있다.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="/assets/img/ai/project/augmentation.png" alt="augumentation" /></p><p>  위의 그림을 보면 좌측 상단의 이미지가 원본 이미지이고 나머지가 <em>뒤틀림</em>, <em>뒤집기</em> 의 방법으로 <strong>증강</strong>한 Mel-Spectrogram의 이미지이다.</p><h3 id="34-data-training">3.4 Data Training</h3><ul><li>학습에 맞게 <strong>전처리</strong>된 데이터를 불러와 Attention이 적용된 Mobile-Net 모델로 학습을 시킨다. 또한 어떤 Convolution Block 위치에 Attention을 적용해야 더 좋은 학습을 할 수 있는지 알기 위하여 Attention을 다르게 적용하여 결과를 확인했다.</ul><blockquote><p>모델에 적용한 Self-Attention 기법인 <code class="language-plaintext highlighter-rouge">CBAM</code>과 Mobile, Embedded System에서 사용하는 CNN 모델인 <code class="language-plaintext highlighter-rouge">Mobile-Net</code>의 내용은 ‘딥러닝 기반 반려견 울음소리 감지와 감정 및 상태 분석(1)’에 명시되어 있다.</p></blockquote><ul><li>먼저, 이번 연구에 사용한 <code class="language-plaintext highlighter-rouge">Convolution Block Attention Module</code>이다.</ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
</pre><td class="rouge-code"><pre><span class="s">"""
    기존의 Self Attention을 경량화한 CONVOLUTION BLOCK ATTENTION MODULE
    @FUNCTION se_block : Squeeze and Excitation Block
    @FUNCTION cbam_block : Convolution Block Attetntion Module
    @FUNCTION channel_attention : Channel Attention
    @FUNCITON Spatial_attention : Spation_attention
"""</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Conv2D</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">GlobalAvgPool2D</span><span class="p">,</span> <span class="n">GlobalMaxPool2D</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Reshape</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Permute</span><span class="p">,</span> <span class="n">Lambda</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Add</span><span class="p">,</span> <span class="n">Activation</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">from</span> <span class="nn">keras.activations</span> <span class="kn">import</span> <span class="n">sigmoid</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="s">"""
    Squeeze-and-Excitation(SE) Block
    @brief : 채널간의 관계를 재종정 시켜줌
    @param input_feature : tensor
"""</span>
<span class="k">def</span> <span class="nf">se_block</span><span class="p">(</span><span class="n">input_feature</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
    
    <span class="n">se_feature</span> <span class="o">=</span> <span class="n">GlobalAvgPool2D</span><span class="p">()(</span><span class="n">input_feature</span><span class="p">)</span>
    <span class="n">channel</span> <span class="o">=</span> <span class="n">input_feature</span><span class="p">.</span><span class="n">_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">se_feature</span> <span class="o">=</span> <span class="n">Reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">channel</span><span class="p">))(</span><span class="n">se_feature</span><span class="p">)</span>
    <span class="n">se_feature</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">channel</span> <span class="o">//</span> <span class="n">ratio</span><span class="p">,</span>
                       <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span>
                       <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'he_normal'</span><span class="p">,</span>
                       <span class="n">use_bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                       <span class="n">bias_initializer</span><span class="o">=</span><span class="s">'zeros'</span><span class="p">)(</span><span class="n">se_feature</span><span class="p">)</span>
    
    <span class="n">se_feature</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span>
                       <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">,</span>
                       <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'he_normal'</span><span class="p">,</span>
                       <span class="n">use_bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                       <span class="n">bias_initializer</span><span class="o">=</span><span class="s">'zeros'</span><span class="p">)(</span><span class="n">se_feature</span><span class="p">)</span>
    
    <span class="n">se_feature</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">multiply</span><span class="p">([</span><span class="n">input_feature</span><span class="p">,</span> <span class="n">se_feature</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">se_feature</span>

<span class="s">"""
    CBAM_BLOCK
    @brief : Convolution Block Attention Module
    @param cbam_feature : input tensor
    @param ratio(int) : channel reduce ratio
    @return cbam_feature : dynamic feature selection
"""</span>
<span class="k">def</span> <span class="nf">cbam_block</span><span class="p">(</span><span class="n">cbam_feature</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
    
    <span class="n">cbam_feature</span> <span class="o">=</span> <span class="n">channel_attention</span><span class="p">(</span><span class="n">cbam_feature</span><span class="p">,</span> <span class="n">ratio</span><span class="p">)</span>
    <span class="n">cbam_feature</span> <span class="o">=</span> <span class="n">spatial_attention</span><span class="p">(</span><span class="n">cbam_feature</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">cbam_feature</span>

<span class="s">"""
    Channel Attention
    @brief : Channel Attention, average pool과 max pool을 사용(파라미터 양을 줄일 수 있음)
            두 가지 pooled feature는 같은 의미를 공유하는 값이기 때문에 하나의 공유된 MLP를 사용
    @param input_feature = input_tensor
    @return cbam_feature
"""</span>
<span class="k">def</span> <span class="nf">channel_attention</span><span class="p">(</span><span class="n">input_feature</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
    
    <span class="c1"># 채널을 먼저 적용
</span>    <span class="n">channel</span> <span class="o">=</span> <span class="n">input_feature</span><span class="p">.</span><span class="n">_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">shared_layer_one</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">channel</span><span class="o">//</span><span class="n">ratio</span><span class="p">,</span>
                             <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span>
                             <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'he_normal'</span><span class="p">,</span>
                             <span class="n">use_bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                             <span class="n">bias_initializer</span><span class="o">=</span><span class="s">'zeros'</span><span class="p">)</span>
    
    <span class="n">shared_layer_two</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span>
                             <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'he_normal'</span><span class="p">,</span>
                             <span class="n">use_bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                             <span class="n">bias_initializer</span><span class="o">=</span><span class="s">'zeros'</span><span class="p">)</span>
    
    <span class="c1"># average pool과 max pool 두 가지를 결합하여 사용
</span>    <span class="n">avg_pool</span> <span class="o">=</span> <span class="n">GlobalAvgPool2D</span><span class="p">()(</span><span class="n">input_feature</span><span class="p">)</span>
    <span class="n">avg_pool</span> <span class="o">=</span> <span class="n">Reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">channel</span><span class="p">))(</span><span class="n">avg_pool</span><span class="p">)</span>
    <span class="n">avg_pool</span> <span class="o">=</span> <span class="n">shared_layer_one</span><span class="p">(</span><span class="n">avg_pool</span><span class="p">)</span>
    <span class="n">avg_pool</span> <span class="o">=</span> <span class="n">shared_layer_two</span><span class="p">(</span><span class="n">avg_pool</span><span class="p">)</span>
    <span class="n">max_pool</span> <span class="o">=</span> <span class="n">GlobalMaxPool2D</span><span class="p">()(</span><span class="n">input_feature</span><span class="p">)</span>
    <span class="n">max_pool</span> <span class="o">=</span> <span class="n">Reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">channel</span><span class="p">))(</span><span class="n">max_pool</span><span class="p">)</span>
    <span class="n">max_pool</span> <span class="o">=</span> <span class="n">shared_layer_one</span><span class="p">(</span><span class="n">max_pool</span><span class="p">)</span>
    <span class="n">max_pool</span> <span class="o">=</span> <span class="n">shared_layer_two</span><span class="p">(</span><span class="n">max_pool</span><span class="p">)</span>
    
    <span class="n">cbam_feature</span> <span class="o">=</span> <span class="n">Add</span><span class="p">()([</span><span class="n">avg_pool</span><span class="p">,</span> <span class="n">max_pool</span><span class="p">])</span>
    <span class="c1"># 가장 중요한 feature를 찾는 것이 목적이 아니기 때문에 mutually exclusive한
</span>    <span class="c1"># softmax 대신 sigmoid를 사용
</span>    <span class="n">cbam_feature</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s">'sigmoid'</span><span class="p">)(</span><span class="n">cbam_feature</span><span class="p">)</span>
    <span class="n">cbam_feature</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">multiply</span><span class="p">([</span><span class="n">avg_pool</span><span class="p">,</span> <span class="n">max_pool</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">cbam_feature</span>

<span class="s">"""
    Spatial Attention
    @brief : 2차원의 spatial attention, single convolution을 사용하여 특징이 보이는 
            channel을 만듬, 정보가 어디에 있는지 중점을 둠
    @param ipnut_feature : input_tensor(Channel-refined feature)
"""</span>
<span class="k">def</span> <span class="nf">spatial_attention</span><span class="p">(</span><span class="n">input_feature</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">):</span>
    
    <span class="n">cbam_feature</span> <span class="o">=</span> <span class="n">input_feature</span>
    
    <span class="n">avg_pool</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="n">K</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">))(</span><span class="n">cbam_feature</span><span class="p">)</span>
    <span class="n">max_pool</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="n">K</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">))(</span><span class="n">cbam_feature</span><span class="p">)</span>
    <span class="n">concat</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">avg_pool</span><span class="p">,</span> <span class="n">max_pool</span><span class="p">])</span>
    <span class="n">cbam_feature</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                          <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
                          <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                          <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span>
                          <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">,</span>
                          <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'he_normal'</span><span class="p">,</span>
                          <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)(</span><span class="n">concat</span><span class="p">)</span>
    
    <span class="n">cbam_feature</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                          <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
                          <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                          <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span>
                          <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">,</span>
                          <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'he_normal'</span><span class="p">)(</span><span class="n">concat</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">layers</span><span class="p">.</span><span class="n">multiply</span><span class="p">([</span><span class="n">input_feature</span><span class="p">,</span> <span class="n">cbam_feature</span><span class="p">])</span>
</pre></table></code></div></div><ul><li>다음으로 <code class="language-plaintext highlighter-rouge">CBAM</code>을 적용한 <code class="language-plaintext highlighter-rouge">Mobile-Net</code>이다.</ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
</pre><td class="rouge-code"><pre><span class="s">"""
    ATTENTION을 적용한 MOBILE NET
    @FUNCTION load_data : pickle 데이터를 로딩하는 함수
    @FUNCTION Mobile_net : 모바일 넷 모델 함수
    @FUNCITON predict : 모델 예측하는 함수
"""</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras</span> <span class="k">as</span> <span class="n">keras</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras.backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">Conv3D</span><span class="p">,</span> <span class="n">DepthwiseConv2D</span><span class="p">,</span> <span class="n">SeparableConv2D</span><span class="p">,</span> <span class="n">Conv3DTranspose</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">MaxPool2D</span><span class="p">,</span> <span class="n">AvgPool2D</span><span class="p">,</span> <span class="n">GlobalAvgPool2D</span><span class="p">,</span> <span class="n">UpSampling2D</span><span class="p">,</span> <span class="n">BatchNormalization</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Concatenate</span><span class="p">,</span> <span class="n">Add</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">ReLU</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">LeakyReLU</span><span class="p">,</span> <span class="n">PReLU</span>
<span class="kn">from</span> <span class="nn">attention_module</span> <span class="kn">import</span> <span class="n">cbam_block</span>

<span class="s">"""
    데이터 로드
    @brief : load Inputs and Targets from pickle data 
    @param data_path(str) : path to pickle file containing data
    @return X(ndarray) : Inputs
    @return y(ndarray) : Targets
"""</span>
<span class="k">def</span> <span class="nf">load_data</span><span class="p">():</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s">"X_final2.pickle"</span><span class="p">,</span> <span class="s">"rb"</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s">"y_final2.pickle"</span><span class="p">,</span> <span class="s">"rb"</span><span class="p">))</span>
    
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">/</span><span class="mf">225.0</span>
    
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

<span class="s">"""
    mobile net 구현
    @brief : Mobile net with Convolution Block Attention Module(CBAM)
            I used cbam at last of convolution when I used it at every conv block,
            the result was worse.
    @return model : Mobile Net Model
"""</span>
<span class="k">def</span> <span class="nf">mobile_net</span><span class="p">(</span><span class="n">input_shape</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">mobile_net_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">DepthwiseConv2D</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>  
        <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">x</span>
    
    <span class="nb">input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">)(</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">mobile_net_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">mobile_net_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">mobile_net_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">mobile_net_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">mobile_net_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">mobile_net_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">mobile_net_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
        
    <span class="n">x</span> <span class="o">=</span> <span class="n">mobile_net_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">mobile_net_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">cbam_block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">GlobalAvgPool2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="n">output</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="s">"""
    학습된 모델로 예측
    @brief : predict data from trained mobile net model
    @param model : Trained classifier
    @param X : Input data
    @param y(int): Target
"""</span>
<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="c1"># sample의 입력 데이터에 차원 추가
</span>    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">...]</span>
    
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    
    <span class="c1"># argmax를 사용해서 index의 최대 값을 얻음
</span>    <span class="n">predicted_index</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">"Target: {}, Predicted label: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">predicted_index</span><span class="p">))</span>

<span class="c1"># 메인 함수
</span><span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    
    <span class="c1"># load data and split to X_train and y_train
</span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>
    
    <span class="c1"># create network
</span>    <span class="n">K</span><span class="p">.</span><span class="n">clear_session</span><span class="p">()</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">model</span><span class="o">=</span> <span class="n">mobile_net</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
    
    <span class="c1"># compile model
</span>    <span class="n">optimiser</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimiser</span><span class="p">,</span>
                  <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span>
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
    
    <span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
    
    <span class="c1"># train model
</span>    <span class="n">hist</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
    
    <span class="n">fig</span><span class="p">,</span> <span class="n">loss_ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
    
    <span class="n">acc_ax</span> <span class="o">=</span> <span class="n">loss_ax</span><span class="p">.</span><span class="n">twinx</span><span class="p">()</span>
    
    <span class="n">loss_ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">hist</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">],</span> <span class="s">'y'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'train loss'</span><span class="p">)</span>
    <span class="n">loss_ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">hist</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'validation loss'</span><span class="p">)</span>
    
    <span class="n">acc_ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">hist</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'acc'</span><span class="p">],</span> <span class="s">'b'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'train_acc'</span><span class="p">)</span>
    <span class="n">acc_ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">hist</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_acc'</span><span class="p">],</span> <span class="s">'g'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'validation_acc'</span><span class="p">)</span>
    
    <span class="n">loss_ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'epoch'</span><span class="p">)</span>
    <span class="n">loss_ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'loss'</span><span class="p">)</span>
    <span class="n">acc_ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'accuracy'</span><span class="p">)</span>
    
    <span class="n">loss_ax</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'upper left'</span><span class="p">)</span>
    <span class="n">loss_ax</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'lower left'</span><span class="p">)</span>
    
    <span class="c1"># evalute model
</span>    <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">Test accuracy:'</span><span class="p">,</span> <span class="n">test_acc</span><span class="p">)</span>
    
    <span class="n">X_to_predict</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="mi">100</span><span class="p">]</span>
    <span class="n">y_to_predict</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="mi">100</span><span class="p">]</span>
    
    <span class="c1"># predict sample
</span>    <span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_to_predict</span><span class="p">,</span> <span class="n">y_to_predict</span><span class="p">)</span>
    
    <span class="n">model</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="s">'path where your model save'</span><span class="p">)</span>
</pre></table></code></div></div></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/nokh9503.github.io/categories/ai/'>AI</a>, <a href='/nokh9503.github.io/categories/deep-learning/'>Deep Learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/nokh9503.github.io/tags/ai/" class="post-tag no-text-decoration" >AI</a> <a href="/nokh9503.github.io/tags/deep-learning/" class="post-tag no-text-decoration" >Deep Learning</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=딥러닝 기반 반려견 울음소리 감지와 감정 및 상태 분석(2) - 코딩이 싫은 컴공&url=https://nokh9503.github.io/nokh9503.github.io/posts/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%B0%98%EB%A0%A4%EA%B2%AC-%EC%9A%B8%EC%9D%8C%EC%86%8C%EB%A6%AC-%EA%B0%90%EC%A7%80%EC%99%80-%EA%B0%90%EC%A0%95-%EB%B6%84%EC%84%9D(2)/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=딥러닝 기반 반려견 울음소리 감지와 감정 및 상태 분석(2) - 코딩이 싫은 컴공&u=https://nokh9503.github.io/nokh9503.github.io/posts/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%B0%98%EB%A0%A4%EA%B2%AC-%EC%9A%B8%EC%9D%8C%EC%86%8C%EB%A6%AC-%EA%B0%90%EC%A7%80%EC%99%80-%EA%B0%90%EC%A0%95-%EB%B6%84%EC%84%9D(2)/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=딥러닝 기반 반려견 울음소리 감지와 감정 및 상태 분석(2) - 코딩이 싫은 컴공&url=https://nokh9503.github.io/nokh9503.github.io/posts/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%B0%98%EB%A0%A4%EA%B2%AC-%EC%9A%B8%EC%9D%8C%EC%86%8C%EB%A6%AC-%EA%B0%90%EC%A7%80%EC%99%80-%EA%B0%90%EC%A0%95-%EB%B6%84%EC%84%9D(2)/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/nokh9503.github.io/posts/%EB%B0%B1%EC%A4%80-1715-%EC%B9%B4%EB%93%9C-%EC%A0%95%EB%A0%AC%ED%95%98%EA%B8%B0/">[백준 1715번] 카드 정렬하기</a><li><a href="/nokh9503.github.io/posts/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%ED%81%90(Queue)/">[자료구조]큐(Queue)</a><li><a href="/nokh9503.github.io/posts/%EB%B0%B1%EC%A4%80-2133-%ED%83%80%EC%9D%BC-%EC%B1%84%EC%9A%B0%EA%B8%B0/">[백준 2133번] 타일 채우기</a><li><a href="/nokh9503.github.io/posts/%EB%B0%B1%EC%A4%80-2839-%EC%84%A4%ED%83%95-%EB%B0%B0%EB%8B%AC/">[백준 2839번] 설탕 배달</a><li><a href="/nokh9503.github.io/posts/%EB%B0%B1%EC%A4%80-1463-1%EB%A1%9C-%EB%A7%8C%EB%93%A4%EA%B8%B0/">[백준 1463번] 1로 만들기</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/nokh9503.github.io/tags/python/">Python</a> <a class="post-tag" href="/nokh9503.github.io/tags/algorithm/">Algorithm</a> <a class="post-tag" href="/nokh9503.github.io/tags/baekjoon/">Baekjoon</a> <a class="post-tag" href="/nokh9503.github.io/tags/dp/">DP</a> <a class="post-tag" href="/nokh9503.github.io/tags/ai/">AI</a> <a class="post-tag" href="/nokh9503.github.io/tags/deep-learning/">Deep Learning</a> <a class="post-tag" href="/nokh9503.github.io/tags/greedy/">Greedy</a> <a class="post-tag" href="/nokh9503.github.io/tags/string/">String</a> <a class="post-tag" href="/nokh9503.github.io/tags/brute-force/">Brute-Force</a> <a class="post-tag" href="/nokh9503.github.io/tags/mathematics/">Mathematics</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/nokh9503.github.io/posts/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%B0%98%EB%A0%A4%EA%B2%AC-%EC%9A%B8%EC%9D%8C%EC%86%8C%EB%A6%AC-%EA%B0%90%EC%A7%80%EC%99%80-%EA%B0%90%EC%A0%95-%EB%B6%84%EC%84%9D(1)/"><div class="card-body"> <span class="timeago small" > Dec 13, 2020 <i class="unloaded">2020-12-13T01:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>딥러닝 기반 반려견 울음소리 감지와 감정 및 상태 분석(1)</h3><div class="text-muted small"><p> Analysis of Emotional Conditions through the Barking of Dogs Based on Deep Learning 이 주제는 대학교 졸업 논문으로 쓴 주제이다. 교수님들과 같이 연구할 수 있는 다양한 주제들이 있었지만 나는 산업에서 다룰 수 있는 주제를 하기를 원해서 스타트업과 같이 진행을 했다. 비록, 초창기 스...</p></div></div></a></div><div class="card"> <a href="/nokh9503.github.io/posts/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%B0%98%EB%A0%A4%EA%B2%AC-%EC%9A%B8%EC%9D%8C%EC%86%8C%EB%A6%AC-%EA%B0%90%EC%A7%80%EC%99%80-%EA%B0%90%EC%A0%95-%EB%B6%84%EC%84%9D(3)/"><div class="card-body"> <span class="timeago small" > Dec 13, 2020 <i class="unloaded">2020-12-13T01:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>딥러닝 기반 반려견 울음소리 감지와 감정 및 상태 분석(3)</h3><div class="text-muted small"><p> 4. 프로젝트 결과 4.1 연구 결과   결론부터 말하자면 Overfitting과 Underfitting이 둘 다 확인할 수 있었다. 그림에서 왼쪽부터 CBAM을 마지막 Convolution Block에 적용한 모델 결과 값, 가운데는 모든 Convolution Block에 CBAM을 적용한 결과 값이다. 마지막으로 오른쪽은 CBAM을 적용하지 ...</p></div></div></a></div><div class="card"> <a href="/nokh9503.github.io/posts/CNN%EC%9D%98-%EA%B5%AC%EC%A1%B0%EC%99%80-%EC%98%88%EC%A0%9C/"><div class="card-body"> <span class="timeago small" > Dec 28, 2020 <i class="unloaded">2020-12-28T01:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>CNN의 구조와 예제</h3><div class="text-muted small"><p> 컨볼루션 신경망(CNN)을 알아가기 전에 영상 인식(Image Recognition)은 영상 안의 물체를 인식하거나 분류하는 것이다. 컴퓨터가 자동으로 영상 안의 사물을 인식할 수 있다면 얼마나 편리한 세상이 올까? 아직까지는 컴퓨터는 인간의 수준만큼 영상을 인식하고 판별하지 못한다. 하지만 최근에 많은 연구들이 활발하게 진행되고 있고 많은 사례들...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/nokh9503.github.io/posts/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%B0%98%EB%A0%A4%EA%B2%AC-%EC%9A%B8%EC%9D%8C%EC%86%8C%EB%A6%AC-%EA%B0%90%EC%A7%80%EC%99%80-%EA%B0%90%EC%A0%95-%EB%B6%84%EC%84%9D(1)/" class="btn btn-outline-primary"><p>딥러닝 기반 반려견 울음소리 감지와 감정 및 상태 분석(1)</p></a> <a href="/nokh9503.github.io/posts/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%B0%98%EB%A0%A4%EA%B2%AC-%EC%9A%B8%EC%9D%8C%EC%86%8C%EB%A6%AC-%EA%B0%90%EC%A7%80%EC%99%80-%EA%B0%90%EC%A0%95-%EB%B6%84%EC%84%9D(3)/" class="btn btn-outline-primary"><p>딥러닝 기반 반려견 울음소리 감지와 감정 및 상태 분석(3)</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2021 <a href="https://twitter.com/username">your_full_name</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy/" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/nokh9503.github.io/tags/python/">Python</a> <a class="post-tag" href="/nokh9503.github.io/tags/algorithm/">Algorithm</a> <a class="post-tag" href="/nokh9503.github.io/tags/baekjoon/">Baekjoon</a> <a class="post-tag" href="/nokh9503.github.io/tags/dp/">DP</a> <a class="post-tag" href="/nokh9503.github.io/tags/ai/">AI</a> <a class="post-tag" href="/nokh9503.github.io/tags/deep-learning/">Deep Learning</a> <a class="post-tag" href="/nokh9503.github.io/tags/greedy/">Greedy</a> <a class="post-tag" href="/nokh9503.github.io/tags/string/">String</a> <a class="post-tag" href="/nokh9503.github.io/tags/brute-force/">Brute Force</a> <a class="post-tag" href="/nokh9503.github.io/tags/mathematics/">Mathematics</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/nokh9503.github.io/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://nokh9503.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
