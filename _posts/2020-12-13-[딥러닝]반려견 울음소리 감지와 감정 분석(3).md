---
title: 딥러닝 기반 반려견 울음소리 감지와 감정 및 상태 분석(3)
author: nokh9503
date: 2020-12-13 00:00:00 +0800
categories: [AI, Deep Learning]
tags: [AI, Deep Learning]
---

## 4. 프로젝트 결과
### 4.1 연구 결과

![test accuracy](/assets/img/ai/project/test_accuracy.png)

&nbsp;&nbsp;결론부터 말하자면 `Overfitting`과 `Underfitting`이 둘 다 확인할 수 있었다. 그림에서 왼쪽부터 `CBAM`을 마지막 Convolution Block에 적용한 모델 결과 값, 가운데는 모든 Convolution Block에 CBAM을 적용한 결과 값이다. 마지막으로 오른쪽은 CBAM을 적용하지 않은 모델의 결과 값이다.

### 4.2 원인

&nbsp;&nbsp;연구 결과 4.1에 대한 결과에 대해서 다음과 같은 문제점이 있었다고 판단한다.
- 데이터의 부족이다. 앞선 3.2 프로젝트 내용에서 언급했듯이 주로 **YouTube**에서 데이터를 추출했다. 길이가 짧은 동영상들이 대부분이었기 때문에 각 동영상에서 추출할 수 있는 데이터들이 부족했다.
- 이에 따라 딥러닝 연구에 필요한 학습 데이터를 만들기 위해 `Data Augumentation`을 했다. 하지만 오히려 데이터를 증강하지 않았을 때보다 더 낮은 _Test Accuracy_ 를 보였다. 일반적인 이미지와는 달리 `Spectrogram`은 소리를 시각화한 도구이다. 따라서 _뒤틀림_ 이나 _뒤집기_ 와 같은 방법으로 데이터를 증강했을 경우, 소리가 바뀌어 더 낮은 정확도가 나왔다고 판단했다.
- 또한 딥러닝 연구로서 **clean**하지 못한 데이터들을 가공했지만 완벽하게 _노이즈_ 와 _무음 구간_ 을 처리하지 못했기 때문에 이와 같은 결과가 나왔다고 생각된다.

### 4.3 데모

&nbsp;&nbsp;Python 오디오 라이브러리인 `pyaudio`를 이용하여 실시간으로 음향을 분석하고 이에 대한 정보를 `Mel-Spectrogram` 이미지로 변환한다. **스택**을 이용하여 초당 프레임을 저장하고 일정한 프레임을 만족하면 스택에 쌓여있는 프레임들을 Mel-Spectrogram 이미지로 저장했다. 또한 변환된 이미지는 학습 모델을 통해서 **실시간**으로 분석 및 예측하게 된다.

```python
import cv2
import numpy as np
import pyaudio
import librosa
import librosa.display
import matplotlib.pyplot as plt
import time
import tensorflow as tf
import tensorflow.keras as keras

CATEGORES = ["angry", "happy", "lonely", "sad"]
model = keras.load_model("yout model path")
rate = 16000
chunk_size = rate // 4

"""
    생성된 데이터를 모델에 맞게 변경함
    @param filepath(str) : path where your image file is
    @return array that has reshaped for predict
"""
def prepare(filepath):
    img_array = cv2.imread(filepath, cv2.IMREAD_COLOR)
    new_array = cv2.resize(img_array, (62, 78))
    return new_array.reshape(-1, 62, 78, 1)

p = pyaudio.PyAudio()
stream = p.open(format=pyaudio.paFloat32,
                channels=1,
                rate=rate,
                input=True,
                input_device_index=1,
                frames_per_buffer=chunk_size)

frames = []
plt.figure(figsize=(10, 4))
do_melspec = librosa.feature.melspectrogram
pwr_to_db = librosa.core.power_to_db

while True:
    start = time.time()
    data = stream.read(chunk_size)
    data = np.fromstring(data, dtype=np.float32)
    melspec = do_melspec(y=data, sr=rate, n_mels=128, fmax=4000)
    norm_melspec = pwr_to_db(melspec, ref=np.max)
    frames.append(norm_melspec)
    
    if len(frames) == 20:
        
        stack = np.hstack(frames)
        librosa.display.specshow(stack, fmax=4000)
        # LOADED AT 'DB FOLDER' WHERE SPECTROGRAM IMAGE IS
        plt.savefig('your save path' + '.jpg', dpi=300)
        prediction = model.predict([prepare('path where your image is')])
        print(CATEGORES[int(prediction[0][0])])
        plt.draw()
        plt.pause(0.0001)
        plt.clf()
        #break
        frames.pop(0)

    t = time.time() - start
```

## 5. 결론

&nbsp;&nbsp;인공지능 분야에 대한 연구가 활발히 이어짐에 따라 인공지능을 이용한 반려동물과 반려인을 위한 서비스 수요의 증대와 관심으로 시장가치가 증가하고 있다. 따라서 인공지능을 이용한 반려동물 서비스 분야는 다양한 방향으로 발전할 것으로 보인다. 더불어 감정 상태를 정확히 인식하고 이를 이용하는 기술인 **HCI(Human-Computer Interaction)**, **로봇공학**, **의료진단** 등 여러 분야에서 활용될 수 있다.

## 6. 참고문헌
김강주, 「반려견 분리불안증 해소 웨어러블 디바이스 구현」, 『한국정보통신설비학회 학술대회』, 2018.  
김원구, 「음성 인식 정보를 사용한 감정 인식」, 『한국지능시스템학회 학술발표 논문집』, 한국지능시스템 학회, 2008.  
박소은, 「Spectrogram을 이용한 CNN 기반 음성 감정인식」, 『대한전기학회』, 2018.  
오일석, 『패턴인식』, 교보문고, 2018.  
유준형, 「모바일 넷 기반 상반신 이미지 분할 기법 연구」, 『한국정보과학회 학술발표논문지』, 한국정보과학회, 2018.  
이명오, 「Channel Attention과 그룹 컨볼루션을 이용한 효율적인 얼굴 감정인식 CNN」, 『정보과학회논문지』, 한국정보과학회, 2019.  
이민규, 「딥 러닝 기반 감정인식 시스템 개발」, 『한국방송미디어공학회 학술발표대회 논문집』, 한국방송미디어공학회, 2017.  
이성주, 「음성인식 시스템을 위한 전처리 기술」, 『한국정보과학회』, 2017.  
이창빈, 「반려동물과 사람간의 유대관계를 돕는 UX 디자인 연구」, 2017.
