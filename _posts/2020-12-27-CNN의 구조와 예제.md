---
title: CNN의 구조와 예제
author: nokh9503
date: 2020-12-27 16:00:00 +0000
categories: [AI, Deep Learning]
tags: [AI, Deep Learning, CNN]
math: true
---

## 컨볼루션 신경망(CNN)을 알아가기 전에

**영상 인식(Image Recognition)** 영상 안의 물체를 인식하거나 분류하는 것이다. 컴퓨터가 자동으로 영상 안의 사물을 인식할 수 있다면 얼마나 편리한 세상이 올까?

아직까지는 컴퓨터는 인간의 수준만큼 영상을 인식하고 판별하지 못한다. 하지만 최근에 많은 연구들이 활발하게 진행되고 있고 많은 사례들을 통해 성능을 인증하고 있기 때문에 가까운 미래에 컴퓨터가 인간처럼 영상을 자유자재로 인식할 수 있는 날이 올 것이다.

## 1. 컨볼루션 신경망(CNN)

`컨볼루션(convolution)`은 영상 처리나 컴퓨터 시각에서는 가장 기본적인 연산이다. 컨볼루션은 주변 화소값들에 **가중치**를 곱해서 더한 후에 이것을 새로운 화소값으로 하는 연산이다. 컨볼루션 연산은 이미지로 부터 어떤 **특징값**을 얻을 때 사용한다.

![CNN의 예](/assets/img/ai/cnn/CNN.png)

맨 앞에 입력값을 나타내는 **입력층** 이 있고 이어서 입력층에서 컨볼루션 연산을 통하여 특징을 뽑아내는 **특징맵(feature map)** 이 존재한다. 특징맵의 출력에는 **활성화 함수(activation function)**  적용된다. 이어서 **풀링(pooling)** 이 적용한다. 풀링 연산은 서브 샘플링이라고도 한다. 컨불루션 레이어와 풀링 레이어는 여러 번 되풀이 된다. 신경망의 맨 끝에는 완전히 연결된 구조의 전통적인 분류 신경망이 있어서 추출된 특징을 바탕으로 물체를 인식한다. 이 과정에서 2차원의 배열은 **1차원 배열**로 변경되고 출력 레이어의 노드들은 다시 활성화 함수를 적용한다.

**가중치**는 작은 2차원 배열로 주어진다. 가중치가 저장된 배열은 흔히 *커널(kernel)*, *필터(filter)*, *마스크(mask)*라 불린다. 마스크의 크기는 일반적으로 3x3, 5x5, 7x7과 같이 홀수이다.

가중치는 2차원 배열에서 각 화소를 중심으로 덮여 씌워진다. 가중치 아래에 있는 값들은 각각 해당되는 가중치의 값들과 곱해져서 더해진다. 이 계산값은 `ReLU()`와 같은 활성화 함수를 통과해서 다음 레이어의 동일한 위치에 저장된다. 이어서 가중치 마스크는 한 칸 이동한다.

## 2. 풀링(Pooling)

**CNN**에서는 컨볼루션 계층을 수행한 후에 풀링층을 두는 경우가 많다. `풀링(Pooling)`은 쉽게 얘기하면 입력 데이터의 크기를 줄이는 것이다. 풀링 계층을 통과하면 대표값을 뽑아 이미지의 크기가 작아진다.

이러한 풀링 연산의 특성으로는 다음을 말할 수 있다.

- 상세 내용에서 요약통계를 추출하여 계층의 크기가 작아지므로 계산이 빨라진다.
- 매개변수가 없기 때문에 학습이 이루어지지 않는다.
- 계층의 크기가 작아진다는 것은 신경망의 매개변수가 작아진다는 것을 의미한다. 따라서 과적합이 나올 가능성이 줄어든다.
- **물체의 작은 공간이동에 대하여 둔감해지게 된다. 따라서 물체 인식이나 영상 검색 등에 효과적이다.**

풀링 연산이 하는 작업 중에서 가장 중요한 것은 물체의 이동에 대하여 둔감하게 하는 것으로 프로그램 혹은 컴퓨터가 이미지 안에 있는 물체를 인식하기 위해서는 물체가 이동하더라도 동일하게 인식해야 한다.

![풀링](/assets/img/ai/cnn/pooling.png)

풀링에는 크게 *최대 풀링*, *평균 풀링*, *가중치 평균 풀링* 등이 있다. 위의 그림은 최대 풀링과 평균 풀링을 나타낸 그림으로 먼저, 최대 풀링은 컨볼루션처럼 윈도우를 움직여서 윈도우 안에 있는 숫자 중에서 가장 큰 값만 출력하는 풀링 연산이다.

위의 `최대 풀링(Max Pooling)`에서 첫 번째 블록은 (29, 15, 0, 100)의 픽셀값으로 이루어진다. 여기서 가장 큰 값인 100 만을 선택하고 다른 값들은 전부 버린다. 이어서 왼쪽의 `평균 풀링(Average Pooling)`에서 첫 번재 블록은 (31, 15, 0, 100)의 픽셀값으로 이루어지고 있으며 위의 값들의 평균은 36이 된다.

컨볼루션 계층을 구현할 때 많은 방법들이 있다. 하나의 컨볼루션 계층에서 여러 개의 필터를 동시에 학습하는 경우도 많다. 아래 컨볼루션 계층을 보자.

![컨볼루션 필터](/assets/img/ai/cnn/filter.png)

여기서 학습되는 것은 필터의 가중치이다. 필터마다 가중치를 가지고 있으므로 필터가 여러 개 존재하면 동시에 여러 개 필터의 가중치들이 학습된다. **필터가 많아지면 자연스럽게 출력층도 많아진다.**

`Keras`를 이용해서 컨볼루션 레이어를 만들면 다음과 같다.

```python
layers.Conv2D(32, (3, 3), activation='relu', input_shape(28, 28, 1))
```

이 함수의 **첫 번째 매개변수가 바로 필터의 개수이다.** 즉, 32가 필터의 개수이고 (3, 3)은 필터의 크기이다. `activation`은 활성화 함수로 ReLU를 사용한다. `input_shape`은 입력의 형태로 반드시 3차원 배열이어야 한다. 왜냐하면 이미지는 *넓이 x 높이 x 색깔*로 되어 있기 때문이다.

## 3. CNN을 이용한 예제

이 코드는 텐서플로우의 대중적인 예제인 MNIST 패션 이미지 코드를 약간 수정한 것이다. 여기서는 크기가 28x28이고 흑백인 MNIST 이미지를 처리하는 CNN을 정의할 것이다.

우선, 전체적인 코드는 아래와 같다.

```python
import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import datasets, layers, models

fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

train_images = train_images.reshape((60000, 28, 28, 1))
test_images  = test_images.reshape((10000, 28, 28, 1))
train_images = train_images / 255.0
test_images  = test_images / 255.0

"""
컨볼루션 신경망 구축
Conv2D와 MaxPooling2D 층을 번갈아 쌓음
노드 활성화 함수 : ReLU
"""
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))

model.summary()

# 모델을 컴파일하고 훈련시킴
model.compile(optimizer = 'adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(train_images, train_labels, epochs=5)

# CNN 모델의 성능을 평가
test_loss, test_acc = model.evaluate(test_images, test_labels)

print('accuracy: ', test_acc)
```

대략 컨볼루션 계층이 어떤 흐름을 갖고 있는지 이해가 될 것이다. 이제 코드를 분석해보자.

제일 먼저 CNN을 구현함에 필요한 라이브러리들을 포함시키는 것이다.

```python
import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import datasets, layers, models
```

그리고 load_data() 함수를 이용하여 훈련 데이터 셋과 테스트 셋, 4개의 넘파이 배열을 가져온다.

```python
fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
```

이미지의 크기는 28x28이고 픽셀 값은 0부터 255사이이다. Keras의 Conv2D 레이어는 기본적으로 **(행, 열, 채널)** 로 되어 있는 텐서를 받는다. 흑백은 채널이 1이고, 컬러인 경우 채널을 3으로 설정한다. 앞의 60000, 10000의 숫자는 이미지 데이터의 개수이다.

```python
train_images = train_images.reshape((60000, 28, 28, 1))
test_images  = test_images.reshape((10000, 28, 28, 1))
```

이미지 픽셀값은 0부터 255라고 했다. 하지만 아직은 정수이기 때문에 직접 대입하면 안 된다. 반드시 0.0과 1.0사이의 실수로 만드는 `데이터 정규화` 작업을 해야한다.

```python
train_images = train_images / 255.0
test_images  = test_images / 255.0
```

데이터의 모든 준비가 끝났으면 이제는 컨볼루션 신경망을 구축해야 한다. 여기서는 Conv2D와 MaxPooling2D 층을 번갈아 쌓아서 컨불루션 신경망을 구축했다. 활성화 함수로는 ReLU()를 사용했다.

이미지를 분류하려면 모델의 마지막에는 `Dense` 계층을 추가하여서 분류하는 기능을 구현해야 한다. Dense 계층은 1차원 배열을 받아야 하므로 3차원 배열을 1차원으로 변환하는 `Flatten` 계층을 추가해야 한다. 이어서 64개의 노드를 가지는 은닉층을 추가하고 끝으로 10개의 범주로 되어 있는 MNIST 이미지를 10개의 노드를 가지는 `소프트맥스(Softmax)` 계층을 추가하여 분류한다. 즉, Dense 층에는 자신이 분류해야 할 범주의 개수를 입력하면 된다.

```python
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))
```

컨볼루션 신경망의 구축이 완성되었으면 이제 자신이 만든 모델을 컴파일하고 훈련시키면 된다. 훈련이 시작되기 전에 모델의 구조를 확인하기 위해

```python
model.summary()

model.compile(optimizer = 'adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(train_images, train_labels, epochs=5)
```

를 통해 내가 설계한 CNN 모델이 맞는지 확인하는 작업을 한다.

![CNN 모델](/assets/img/ai/cnn/model.png)

참고로 학습되는 parameter 개수를 구하는 방법은 다음과 같다.

> (input channel 수 x convolution 가중치 + 1) x output channel

입력 채널이 3개, 출력 채널이 8개, 필터 혹은 커널이 5x5로 주어진 상황이라면 파라미터의 개수는

> (3 x (5 x 5) + 1) x 8 =608

이 된다.

다시 돌아와서 모델의 훈련이 다 끝났으면 학습이 잘 됐는지 알아야 한다. 즉, CNN 모델의 성능을 평가해야 한다.

```python
test_loss, test_acc = model.evaluate(test_images, test_labels)

print('accuracy: ', test_acc)
```

![모델 평가](/assets/img/ai/cnn/evaluate.png)

테스트 셋에 대하여 정확도가 약 91% 정도인 것을 확인할 수 있다.

지금까지 간단하게 컨볼루션 신경망의 예제와 구조를 통해서 CNN을 알아봤다. CNN은 지금도 활발하게 연구되고 있는 분야이며 점점 더 높은 성능을 자랑하는 많은 종류들의 CNN들이 발표되고 있다. 예를 들면 *Inception*, *Yolo*, *Mobile Net*, *Alex Net* 등이 있으며 Classification을 넘어서 Voice Recognition, Detection, Real Time 등 많은 분야에서도 활용되고 있다.

차후에는 여러 CNN의 종류들과 수학적으로 컨볼루션 신경망을 알아보는 시간을 갖도록 하겠다. 그리고 이러한 CNN을 활용하여 토이 프로젝트를 진행해보겠다.